{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Lorena Barbosa Antunes Da Silva\n",
    "\n",
    "Nome: Jos√© Edson Mendon√ßa Ribeiro Lima Ara√∫jo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\loren\\anaconda3\\lib\\site-packages (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "!pip install emoji\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\loren\\Repositorios\\CDados_Projeto1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Peaky Blinders.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peaky fucking blinders foi a melhor coisa que ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@limawt1 peaky blinders est√° vindo em breve!! ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gente cancela ele me seguiu de outro instagram...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at√© eu que n√£o sou fumante fico com vontade de...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tou a curtir bue de peaky blinders</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classifica√ß√£o\n",
       "0  peaky fucking blinders foi a melhor coisa que ...            1.0\n",
       "1  @limawt1 peaky blinders est√° vindo em breve!! ...            0.0\n",
       "2  gente cancela ele me seguiu de outro instagram...            0.0\n",
       "3  at√© eu que n√£o sou fumante fico com vontade de...            0.0\n",
       "4                 tou a curtir bue de peaky blinders            1.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "linha=np.arange(0,300,1)\n",
    "train=train.iloc[linha,[0,1]]\n",
    "train.head(5)\n",
    "#train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>viciada em peaky blinders üñ§</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>@pedropossobom peaky blinders mastermind \\nmei...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>@italoverdose peaky blinders est√° vindo em bre...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>a gente fuma tbem, somos os peaky blinders htt...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>o lado bom de t√° com covid e que eu t√¥ maraton...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Classifica√ß√£o\n",
       "195                        viciada em peaky blinders üñ§            1.0\n",
       "196  @pedropossobom peaky blinders mastermind \\nmei...            1.0\n",
       "197  @italoverdose peaky blinders est√° vindo em bre...            0.0\n",
       "198  a gente fuma tbem, somos os peaky blinders htt...            0.0\n",
       "199  o lado bom de t√° com covid e que eu t√¥ maraton...            1.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "linha=np.arange(0,200,1)\n",
    "test=test.iloc[linha,[0,1]]\n",
    "test.head(5)\n",
    "test.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "ESCREVA AQUI...\n",
    "\n",
    "Produto: S√©rie Peaky Blinders, consideramos relevante qualquer coment√°rio positivo ou negativo, relacionados a s√©rie mostrando que est√£o assistindo ou indicando. Exemplo: \"N√£o curti assistir Peaky Blinders\", \"@user1 vc precisa assistir peaky blinders\", \"acabei de maratonar essa serie peaky blinders\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13\n",
    "\n",
    "\n",
    "import re \n",
    "\n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    limpa_emoji=' '.join(emoji.get_emoji_regexp().split(text))\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', limpa_emoji)\n",
    "    \n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comentarios_relevantes=[]\n",
    "comentarios_irrelevantes=[]\n",
    "for i in range(0,300,1):\n",
    "    comentario=cleanup(train.Treinamento[i]).lower().split()\n",
    "    if train.Classifica√ß√£o[i]==1:\n",
    "        comentarios_relevantes.append(comentario)\n",
    "    elif train.Classifica√ß√£o[i]==0:\n",
    "        comentarios_irrelevantes.append(comentario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_irrelevantes=[]\n",
    "l_relevantes=[]\n",
    "for comentario in comentarios_irrelevantes:\n",
    "    lista_remocao=[]\n",
    "    for palavra in comentario:\n",
    "        if  palavra[0]=='@' or 'htt' == palavra[0:3]:\n",
    "            lista_remocao.append(palavra)\n",
    "    for palavra in lista_remocao:\n",
    "        comentario.remove(palavra)\n",
    "    for palavra in comentario:\n",
    "        l_irrelevantes.append(palavra)\n",
    "        \n",
    "for comentario in comentarios_relevantes:\n",
    "    lista_remocao=[]\n",
    "    for palavra in comentario:\n",
    "        if  palavra[0]=='@' or 'htt' == palavra[0:3]:\n",
    "            lista_remocao.append(palavra)\n",
    "    for palavra in lista_remocao:\n",
    "        comentario.remove(palavra)\n",
    "\n",
    "for comentario in comentarios_irrelevantes:\n",
    "    for palavra in comentario:\n",
    "        l_irrelevantes.append(palavra)\n",
    "for comentario in comentarios_relevantes:\n",
    "    for palavra in comentario:\n",
    "        l_relevantes.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_l_relevantes=  pd.Series(l_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_l_irrelevantes=  pd.Series(l_irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_relevantes = s_l_relevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_irrelevantes = s_l_irrelevantes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = comentarios_relevantes + comentarios_irrelevantes\n",
    "lista_total = l_irrelevantes + l_relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_l_total = pd.Series(lista_total)\n",
    "tab_l_total= s_l_total.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_relevantes=[]\n",
    "test_irrelevantes=[]\n",
    "test_total = []\n",
    "\n",
    "for i in range(0,200,1):\n",
    "    comentarios_test=cleanup(test.Teste[i]).lower().split()\n",
    "    \n",
    "    if test.Classifica√ß√£o[i]==1:\n",
    "        test_relevantes.append(comentarios_test)\n",
    "        \n",
    "    elif test.Classifica√ß√£o[i]==0:\n",
    "        test_irrelevantes.append(comentarios_test)\n",
    "        \n",
    "    test_total.append(comentarios_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_relevante = len(l_relevantes)/len(lista_total)\n",
    "P_irrelevante = len(l_irrelevantes)/len(lista_total)\n",
    "P_relevante + P_irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_relevante_dado_comentario = []\n",
    "P_irrelevante_dado_comentario = []\n",
    "relevancia_classificador = []\n",
    "i=0\n",
    "\n",
    "while i < len(test_total): \n",
    "    P_comentario_dado_relevante = 1\n",
    "    P_comentario_dado_irrelevante = 1\n",
    "   \n",
    "    for palavra in test_total[i]:\n",
    "        if palavra not in l_relevantes:\n",
    "            tab_relevantes[palavra]=0\n",
    "            \n",
    "        if palavra not in l_irrelevantes:\n",
    "            tab_irrelevantes[palavra]=0\n",
    "            \n",
    "        P_comentario_dado_relevante *= (tab_relevantes[palavra]+1)/(len(l_relevantes)+len(lista_total))\n",
    "        P_comentario_dado_irrelevante *= (tab_irrelevantes[palavra]+1)/(len(l_irrelevantes)+len(lista_total))\n",
    "    \n",
    "    P_relevante_dado_comentario.append(P_comentario_dado_relevante*P_relevante)\n",
    "    P_irrelevante_dado_comentario.append(P_comentario_dado_irrelevante*P_irrelevante)\n",
    "    \n",
    "    if P_relevante_dado_comentario[i] > P_irrelevante_dado_comentario[i]:\n",
    "        relevancia_classificador.append(1)\n",
    "        \n",
    "    else:\n",
    "        relevancia_classificador.append(0)\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Relevancia_Classificador\"]=relevancia_classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Relevancia_Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>31.5</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Relevancia_Classificador     0     1\n",
       "Classifica√ß√£o                       \n",
       "0.0                       49.0   6.0\n",
       "1.0                       31.5  13.5"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matriz_de_Compara√ß√£o = pd.crosstab(test[\"Classifica√ß√£o\"] , test[\"Relevancia_Classificador\"], normalize=True)*100\n",
    "Matriz_de_Compara√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia:62.50%\n"
     ]
    }
   ],
   "source": [
    "print(\"Acur√°cia:{0:.2f}%\".format(Matriz_de_Compara√ß√£o[0][0] + Matriz_de_Compara√ß√£o[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
